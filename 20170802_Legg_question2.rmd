---
title: "Lab3 Q2"
author: "Michelle Kim, Sue Yang, Legg Yeung"
date: "August 2, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# copied
library(moments)
library(psych)
library(forecast)
library(tseries)
library(effects)

unem.data = read.csv("UNRATENSA.csv", header = T)
auto.data = read.csv("TOTALNSA.csv", header = T)
```

#Question 2: SARIMA

It is Dec 31, 2016 and you work for a non-partisan think tank focusing on the state of the US economy. You are interested in forecasting the unemployment rate through 2017 (and then 2020) to use it as a benchmark against the incoming administrations economic performance. Use the dataset UNRATENSA.csv and answer the following:

(A) Build a SARIMA model using the unemployment data and produce a 1 year forecast and then a 4 year forecast. Because it is Dec 31, 2016, leave out 2016 as your test data.

```{r}
unem.train = unem.data[0:816,]
unem.test = unem.data[817:834,]
```

```{r}
unem.train.ts = ts(unem.train$UNRATENSA)
unem.test.ts = ts(unem.test$UNRATENSA)
```

## Construct and Loop through search spaces

From the EDA, we speculated the following models:

  - Seasonal Differenced Series: SARIMA(4,0,1)(3,1,Q)
  - First Differenced Series: SARIMA(9,1,q)(1,0,1)
  - First and Seasonal Differenced Series: SARIMA(4,1,0)(0,1,1)

Because the EDA was inconclusive on differencing strategies, we define the following search spaces:

  - Seasonal Differenced Series: SARIMA(1:4,0,0:3)(0:4,1,0:3)
  - First Differenced Series: SARIMA(1:9,1,0:3)(0:3,0,0:3) 
  - First and Seasonal Differenced Series: SARIMA(0:5,1,0:3)(0:3,1,0:3)

where SARIMA(p,d,q)(P,D,Q)_12 is the general form of model.

```{r,eval = FALSE}
# READ LOOP RESULTS FROM THE CSV FILES

# Seasonal Differenced Series : SARIMA(1:4,0,0:3)(0:4,1,0:3)
bestAIC <- 10000 
unem.diff12.df = data.frame("p" = 0, "q" = 0, "P" = 0, "Q" = 0, "aic" = bestAIC)

for(p in 1:4){
  for (q in 0:3){
    for (P in 0:4){
      for (Q in 0:3){
        cat(p,q,P,Q,"\n")
        try(m <- Arima(unem.train.ts, order = c(p, 0, q), seasonal = list(order = c(P, 1, Q), period = 12)))
        
        if(m$aic < bestAIC) # update if this model attain better aic
        { bestAIC = m$aic
          bestFit = m
          bestModel = c( p, q, P, Q)
          cat(p,q,P,Q,as.numeric(bestAIC), "\n")
          unem.diff12.df = rbind(unem.diff12.df, 
                                 data.frame("p" = p, "q" = q, "P" = P, "Q" = Q, "aic" = bestAIC))} 
      }
    }
  }
}

unem.diff12.df = unem.diff12.df[seq(dim(unem.diff12.df)[1],1),]
write.csv(x = unem.diff12.df, file = "unem.diff12.df.csv")


# First Differenced Series: SARIMA(9,1,0:3)(0:3,0,0:3) 

bestAIC <- 10000 

unem.diff.df = data.frame("p" = 0, "q" = 0, "P" = 0, "Q" = 0, "aic" = bestAIC)

for(p in 1:9){
  for (q in 0:3){
    for (P in 0:3){
      for (Q in 0:3){
        cat(p,q,P,Q,"\n")
        try(m <- Arima(unem.train.ts, order = c(p, 1, q), seasonal = list(order = c(P, 0, Q), period = 12)),
            silent = TRUE)
        
        if(m$aic < bestAIC) # update if this model attain better aic
        { bestAIC = m$aic
        bestFit = m
        bestModel = c( p, q, P, Q)
        cat(p,q,P,Q,as.numeric(bestAIC), "\n")
        unem.diff.df = rbind(unem.diff.df, 
                               data.frame("p" = p, "q" = q, "P" = P, "Q" = Q, "aic" = bestAIC))} 
      }
    }
  }
}

unem.diff.df = unem.diff.df[seq(dim(unem.diff.df)[1],1),]
write.csv(x = unem.diff.df, file = "unem.diff.df.csv")



# First and Seasonal Differenced Series: SARIMA(0:5,1,0:3)(0:3,1,0:3) 

bestAIC <- 10000 

unem.diff.diff12.df = data.frame("p" = 0, "q" = 0, "P" = 0, "Q" = 0, "aic" = bestAIC)

for(p in 0:5){
  for (q in 0:3){
    for (P in 0:3){
      for (Q in 0:3){
        cat(p,q,P,Q,"\n")
        try(m <- Arima(unem.train.ts, order = c(p, 1, q), seasonal = list(order = c(P, 1, Q), period = 12)),
            silent = TRUE)
        
        if(m$aic < bestAIC) # update if this model attain better aic
        { bestAIC = m$aic
        bestFit = m
        bestModel = c( p, q, P, Q)
        cat(p,q,P,Q,as.numeric(bestAIC), "\n")
        unem.diff.diff12.df = rbind(unem.diff.diff12.df, 
                             data.frame("p" = p, "q" = q, "P" = P, "Q" = Q, "aic" = bestAIC))} 
      }
    }
  }
}

unem.diff.diff12.df = unem.diff.diff12.df[seq(dim(unem.diff.diff12.df)[1],1),]
write.csv(x = unem.diff.diff12.df, file = "unem.diff.diff12.df.csv")
```

### Seasonal Differenced Search Result

```{r}
unem.diff12.df = read.csv("unem.diff12.df.csv")
cat("Top candidates for seasonal differenced model: d = 0, D = 1 \n")
unem.diff12.df[,3:7]
```

### First Differenced Search Result

```{r}
unem.diff.df = read.csv("unem.diff.df.csv")
cat("Top candidates for first differenced model: d = 1, D = 0 \n")
unem.diff.df[,3:7]
```

### First and Seasonal Differenced Search Result

```{r}
unem.diff.diff12.df = read.csv("unem.diff.diff12.df.csv")
cat("Top candidates for first and seasonal differenced model: d = 1, D = 1 \n")
unem.diff.diff12.df[,3:7]
```

Using the results above, we attempt to simplify the order of the top candidate for each search space by comparing their residuals against respective lower order models.

### Seasonal Differenced Models ( d = 0 , D = 1)

```{r, warning=FALSE}
# top (4,0,3)(0,1,1)
m.diff12.1 <- Arima(unem.train.ts, order = c(4, 0, 3), 
                    seasonal = list(order = c(0, 1, 1), period = 12))

# 2nd (3,0,1)(0,1,1)
m.diff12.2 <- Arima(unem.train.ts, order = c(3, 0, 1), 
                    seasonal = list(order = c(0, 1, 1), period = 12))

# 3rd (2,0,3)(2,1,3)
#m.diff12.3 <- Arima(unem.train.ts, order = c(2, 0, 3), 
#                    seasonal = list(order = c(2, 1, 3), period = 12))
# 4th (2,0,2)(3,1,3)
#m.diff12.4 <- Arima(unem.train.ts, order = c(3, 0, 1), 
#                    seasonal = list(order = c(0, 1, 1), period = 12))
# 5th (2,0,2)(0,1,1)
#m.diff12.5 <- Arima(unem.train.ts, order = c(2, 0, 2), 
#                    seasonal = list(order = c(0, 1, 1), period = 12))
# 6th (2,0,1)(3,1,3)
#m.diff12.6 <- Arima(unem.train.ts, order = c(2, 0, 1), 
#                    seasonal = list(order = c(3, 1, 3), period = 12))

# 7th (2,0,1)(0,1,1)
m.diff12.7 <- Arima(unem.train.ts, order = c(2, 0, 1), 
                    seasonal = list(order = c(0, 1, 1), period = 12))

# 8th (1,0,3)(2,1,3)
m.diff12.8 <- Arima(unem.train.ts, order = c(1, 0, 3), 
                    seasonal = list(order = c(2, 1, 3), period = 12))
```

```{r}
# Function to print residual charts
print_resid_chart <- function(mod) {
  cat("Model SARIMA ", c(mod$arma[1], mod$arma[6], mod$arma[2],
                         mod$arma[3], mod$arma[7], mod$arma[4]) , ":\n")
  cat("AIC: ",(mod$aic),"\n")
  cat("BIC: ",(mod$bic),"\n")
  par(mfrow=c(3,1))
  hist(mod$residuals)
  acf(mod$residuals, 156)
  pacf(mod$residuals, 156)
}
```

```{r}
# top (4,0,3)(0,1,1)
print_resid_chart(m.diff12.1)

#print_resid_chart(m.diff12.2)
#print_resid_chart(m.diff12.3,2)
#print_resid_chart(m.diff12.4,2)
#print_resid_chart(m.diff12.5,2)
#print_resid_chart(m.diff12.6,2)

# 7th (2,0,1)(0,1,1)
print_resid_chart(m.diff12.7)

# 8th (1,0,3)(2,1,3)
print_resid_chart(m.diff12.8)
```

```{r}
# top (4,0,3)(0,1,1)
Box.test(m.diff12.1$residuals, lag=25, type = c("Ljung-Box"))
# 7th (2,0,1)(0,1,1)
Box.test(m.diff12.7$residuals, lag=25, type = c("Ljung-Box"))
```

For seasonal differenced models, we reduced from the top AIC candidate, SARIMA(4,0,3)(0,1,1) to 7th candidate SARIMA(2,0,1)(0,1,1) and retain white noise residual behavior. 8th candidate SARIMA(1,0,3)(2,1,3) starts to show significant pacfs at lag 4 and 5, therefore we stop searching from there downwards. We will keep these two candidates to compare out of sample performance:

	- SARIMA(4,0,3)(0,1,1)
	- SARIMA(2,0,1)(0,1,1) 
	
We perform the Box-Ljung test above for our residual series to see if residuals for these models are independently distributed. Test hypothesis is as follows:

  - Ho : The residuals are independently distributed
  - Ha : The residuals are not independently distributed 
  
  - The tests fail to reject the null hypothesis, thus support that the residuals resemble white noise.

### First Differenced Models ( d = 1 , D = 0)

```{r, warning=FALSE}
# top (8,1,3)(1,0,1)
m.diff.1 <- Arima(unem.train.ts, order = c(8, 1, 3), 
                  seasonal = list(order = c(1, 0, 1), period = 12))

# 2nd (2,1,3)(2,0,1)
#m.diff.2 <- Arima(unem.train.ts, order = c(2, 1, 3), seasonal = list(order = c(2, 0, 1), period = 12))

# 3rd (2,1,1)(1,0,1)
m.diff.3 <- Arima(unem.train.ts, order = c(2, 1, 1), seasonal = list(order = c(1, 0, 1), period = 12))

# 4th (1,1,2)(1,0,1)
#m.diff.4 <- Arima(unem.train.ts, order = c(1, 1, 2), seasonal = list(order = c(1, 0, 1), period = 12))
# 5th (1,1,1)(3,0,3)
#m.diff.5 <- Arima(unem.train.ts, order = c(1, 1, 1), seasonal = list(order = c(3, 0, 3), period = 12))
 
# 6th (1,1,1)(1,0,1)
m.diff.6 <- Arima(unem.train.ts, order = c(1, 1, 1), 
                  seasonal = list(order = c(1, 0, 1), period = 12))

# 7th (1,1,0)(1,0,1)
m.diff.7 <- Arima(unem.train.ts, order = c(1, 1, 0), 
                  seasonal = list(order = c(1, 0, 1), period = 12))

# 8th (1,1,0)(1,0,0)
# m.diff.8 <- Arima(unem.train.ts, order = c(1, 1, 0), 
#                  seasonal = list(order = c(1, 0, 0), period = 12))
```


```{r}
# top (8,1,3)(1,0,1)
print_resid_chart(m.diff.1)

#print_resid_chart(m.diff.2)

# third (2,1,1)(1,0,1)
print_resid_chart(m.diff.3)

# 4th (1,1,2)(1,0,1)
#print_resid_chart(m.diff.4)
# 5th (1,1,1)(3,0,3)
#print_resid_chart(m.diff.5)

# 6th (1,1,1)(1,0,1)
print_resid_chart(m.diff.6)

# 7th (1,1,0)(1,0,1)
print_resid_chart(m.diff.7)

# 8th (1,1,0)(1,0,0)
# print_resid_chart(m.diff.8)
```

```{r}
# top (8,1,3)(1,0,1)
Box.test(m.diff.1$residuals, lag=25, type = c("Ljung-Box"))
# third (2,1,1)(1,0,1)
Box.test(m.diff.3$residuals, lag=25, type = c("Ljung-Box"))
# 6th (1,1,1)(1,0,1)
Box.test(m.diff.6$residuals, lag=25, type = c("Ljung-Box"))
```

For first differenced models, we reduced from the top AIC candidate, SARIMA(8,1,3)(1,0,1) to 3rd candidate SARIMA(2,1,1)(1,0,1) and retain white noise residual behavior. 6th candidate SARIMA(1,1,1)(1,0,1) is still satisfactory but more of its lags are slightly closer to the cut-off. 7th candidate SARIMA(1,1,0)(1,0,1) starts to show significant pacfs at lag 2, 3 and 5, and 8th candidate SARIMA(1,1,0)(1,0,0) starts to show significant pacfs at seasonal lags, therefore we stop searching from there downwards. We will keep the first three candidates to compare out of sample performance:

	- SARIMA(8,1,3)(1,0,1)
	- SARIMA(2,1,1)(1,0,1)
	- SARIMA(1,1,1)(1,0,1)
	
The Box-Ljung tests above rejected the null hypothesis for all three models to support that our residuals are independently distributed.


### First and Seasonal Differenced Models ( d = 1 , D = 1)

```{r, warning=FALSE}
# top (2,1,3)(1,1,1)
m.diff.diff12.1 <- Arima(unem.train.ts, order = c(2, 1, 3), 
                         seasonal = list(order = c(1, 1, 1), period = 12))

# 2nd (2,1,1)(0,1,1)
m.diff.diff12.2 <- Arima(unem.train.ts, order = c(2, 1, 1), 
                         seasonal = list(order = c(0, 1, 1), period = 12))
# 3rd (1,1,2)(3,1,3)
m.diff.diff12.3 <- Arima(unem.train.ts, order = c(1, 1, 2), 
                         seasonal = list(order = c(3, 1, 3), period = 12))

# 4th (1,1,2)(0,1,1)
#m.diff.diff12.4 <- Arima(unem.train.ts, order = c(1, 1, 2), 
#                         seasonal = list(order = c(0, 1, 1), period = 12))
# 5th (1,1,1)(3,1,3)
#m.diff.diff12.5 <- Arima(unem.train.ts, order = c(1, 1, 1), 
#                         seasonal = list(order = c(3, 1, 3), period = 12))
# 6th (1,1,1)(0,1,1)
#m.diff.diff12.6 <- Arima(unem.train.ts, order = c(1, 1, 1), 
#                          seasonal = list(order = c(0, 1, 1), period = 12))

# 7th (0,1,3)(2,1,3)
m.diff.diff12.7 <- Arima(unem.train.ts, order = c(0, 1, 3), 
                         seasonal = list(order = c(2, 1, 3), period = 12))
```

```{r}
# top (2,1,3)(1,1,1)
print_resid_chart(m.diff.diff12.1)

# 2nd (2,1,1)(0,1,1)
print_resid_chart(m.diff.diff12.2)
# 3rd (1,1,2)(3,1,3)
print_resid_chart(m.diff.diff12.3)

# 4th (1,1,2)(0,1,1)
#print_resid_chart(m.diff.diff12.4)
# 5th (1,1,1)(3,1,3)
#print_resid_chart(m.diff.diff12.5)
# 6th (1,1,1)(0,1,1)
#print_resid_chart(m.diff.diff12.6)

# 7th (0,1,3)(2,1,3)
print_resid_chart(m.diff.diff12.7)
```

```{r}
# top (2,1,3)(1,1,1)
Box.test(m.diff.diff12.1$residuals, lag=25, type = c("Ljung-Box"))
# 2nd (2,1,1)(0,1,1)
Box.test(m.diff.diff12.2$residuals, lag=25, type = c("Ljung-Box"))
# 3rd (1,1,2)(3,1,3)
Box.test(m.diff.diff12.3$residuals, lag=25, type = c("Ljung-Box"))
```

For first and seasonal differenced models, we reduced from the top AIC candidate, SARIMA(2,1,3)(1,1,1) to 2nd candidate SARIMA(2,1,1)(0,1,1) and 3rd candidate(1,1,2)(3,1,3) with similar white noise behaviors. The 4th candidate SARIMA(1,1,2)(0,1,1), 5th candidate SARIMA(1,1,1)(3,1,3) and 6th SARIMA(1,1,1)(0,1,1) are still satisfactory but more of their lags are slightly closer to the cut-off (plots skipped here). 7th candidate SARIMA(0,1,3)(2,1,3) starts to show significant pacfs at lag 5 and 6, therefore we stop searching from there downwards. We will keep these three candidates to compare out of sample performance:

	- SARIMA(2,1,3)(1,1,1)
	- SARIMA(2,1,1)(0,1,1)
	- SARIMA(1,1,2)(3,1,3)

The Box-Ljung tests above rejected the null hypothesis for all three models to support that our residuals are independently distributed.

	
### Compare models based on out of sample errors uptil Jun 2017

(A.i)How well does your model predict the unemployment rate up until June 2017? 

```{r, eval = F}
# candidate models
# SARIMA(4,0,3)(0,1,1) m.diff12.1
# SARIMA(2,0,1)(0,1,1) m.diff12.7
# SARIMA(8,1,3)(1,0,1) m.diff.1
# SARIMA(2,1,1)(1,0,1) m.diff.3
# SARIMA(1,1,1)(1,0,1) m.diff.6
# SARIMA(2,1,3)(1,1,1) m.diff.diff12.1
# SARIMA(2,1,1)(0,1,1) m.diff.diff12.2
# SARIMA(1,1,2)(3,1,3) m.diff.diff12.3

candidate_mods = list(m.diff12.1,m.diff12.7,m.diff.1,m.diff.3,m.diff.6,m.diff.diff12.1,m.diff.diff12.2,m.diff.diff12.3)
```

```{r}
# function to get RMSE
get_RMSE = function(test.df, mod, ahead){
  f = forecast(mod, ahead)$mean
  sq.error = (test.df$UNRATENSA - f)^2
  rmse = sqrt(mean(sq.error))
  return (data.frame( "p" = mod$arma[1], "d" = mod$arma[6], "q" = mod$arma[2],
                      "P" = mod$arma[3], "D" = mod$arma[7], "Q" = mod$arma[4],
                      "RMSE" = rmse))
}
```

```{r}
RMSE.df = data.frame()
for (i in 1:length(candidate_mods)) {
  add.df = get_RMSE(unem.test, candidate_mods[[i]], 18)
  RMSE.df = rbind(RMSE.df, add.df)
}
RMSE.df = RMSE.df[order(RMSE.df$RMSE),]
RMSE.df
```

Out of sample errors tells us that SARIMA(2,1,1)(1,0,1), SARIMA(2,1,1)(0,1,1), SARIMA(1,1,1)(1,0,1) and SARIMA(1,1,2)(3,1,3) perform superior to the other candidates and their RMSEs are very close. We plot their forecasts to further compare these three.

```{r}
unem.actual.ts = ts(unem.data$UNRATENSA)
# (2,1,1)(1,0,1)
f.diff.3<-forecast(m.diff.3,18)
# (2,1,1)(0,1,1)
f.diff.diff12.2<-forecast(m.diff.diff12.2,18)
# (1,1,1)(1,0,1)
f.diff.6<-forecast(m.diff.6,18)
# (1,1,2)(3,1,3)
f.diff.diff12.3<-forecast(m.diff.diff12.3,18)
```

```{r}
par(mfrow = c(2,2))

plot(f.diff.3, xlim = c(818,834))
lines(unem.actual.ts,type="l",col="red")
plot(f.diff.diff12.2, xlim = c(818,834))
lines(unem.actual.ts,type="l",col="red")
plot(f.diff.6, xlim = c(818,834))
lines(unem.actual.ts,type="l",col="red")
plot(f.diff.diff12.3, xlim = c(818,834))
lines(unem.actual.ts,type="l",col="red")
```

All four models predict closely to the test data. SARIMA(2,1,1)(1,0,1) performing the closest in the time plots and it has the lowest RMSE of 0.147. We will use this model to forecast unemployment rate until 2020. Before that, the model specification is given by the following:

```{r}
m.diff.3$coef
```

```{r}
# characteristic equation for differenced AR component
Mod(polyroot(c(1,-0.5986,-0.1241)))
# characteristic equation for differenced SAR component
Mod(polyroot(c(1,-0.9918)))
# characteristic equation for differenced MA component
Mod(polyroot(c(1,-0.4846)))
# characteristic equation for differenced SMA component
Mod(polyroot(c(1,-0.7583)))
```


$$(1 - \Theta B^{12})(1 - \theta_1 B - \theta_2 B^2)(1-B)x_t = (1 + \Phi B^{12})(1 + \phi B)w_t$$
where $\Theta = +0.9918$, $\theta_1 = + 0.5986$, $\theta_2 = +0.1241$, $\Phi = -0.7583$, $\phi = -0.4846$.

  - A unit root on the left specified by $(1-B)$, which was taken care of by first differencing. 
  
  - The first differenced AR component has characteristic equation $1 - 0.5986 B - 0.1241 B^2 = 0$, the roots for $B$ are 1.313 and 6.136. The first differenced seasonal component has characteristic equation $1 - 0.9918 B^{12} = 0$, the root for $B^{12}$ is 1.008. All roots exceed unity which means the first differenced series is stationary.
  
  - The first differenced MA component has characteristic equation $1 - 0.4846 B= 0$, the roots for $B$ is 2.064. The first differenced seasonal MA component has characteristic equation $1 - 0.7583 B^{12}= 0$, the roots for $B^{12}$ is 1.319. All roots exceed unity which means the first differenced series is invertible.
  

### Forecast until 2020

(A.ii) What does the unemployment rate look like at the end of 2020? How credible is this estimate?

```{r}
#817 2016 Jan
#forecast.sarima.ts = ts(forecast(m.diff.3,h=60)$mean, start = c(2016,1), frequency = 12)
  
par(mfrow = c(2,1))

#forecast out to Dec 2020 
plot(forecast(m.diff.3,h=60))
plot(forecast(m.diff.3,h=60),xlim=c(800,876))
```

```{r}
f.diff.3.2020<-forecast(m.diff.3,h=60)
cat("Forecast 2020 December -- Expected Value", 
    f.diff.3.2020$mean[60], "\n")
cat("Forecast 2020 December -- 95% Lower Confidence Bound", 
    f.diff.3.2020$lower[60,2], "\n")
cat("Forecast 2020 December -- 95% Upper Confidence Bound", 
    f.diff.3.2020$upper[60,2], "\n")
```

As we can see from the forecast time plots above, the confidence bound of forecast expand drastically towards 2020. Although the mean value is expected to be $2.5835$, this estimate is not very credible. The wide point estimates of confidence bound covers zero so we don't even know if unemployment will be positive or negative!


(B) Build a linear time-regression and incorporate seasonal effects. Be sure to evaluate the residuals and assess this model on the basis of the assumptions of the classical linear model, and then produce a 1 year and a 4 year forecast.

```{r}
# Kernel smoothing
unem.k.smooth.widest = ksmooth(time(unem.ts), 
                             unem.ts, kernel = c("normal"), 
                             bandwidth = 50)

unem.k.smooth.wide = ksmooth(time(unem.ts), 
                             unem.ts, kernel = c("normal"), 
                             bandwidth = 25)

unem.k.smooth.narrow = ksmooth(time(unem.ts), 
                               unem.ts, kernel = c("normal"), 
                               bandwidth = 10)
# Make plot
plot(unem.ts, col = "gray", ylab = "Unemployment Rate",
     main = "Unemployment Rate - Quadratic time trend")
lines(unem.k.smooth.widest$x, unem.k.smooth.widest$y, 
      col = "black", lty = "dotted")
lines(unem.k.smooth.wide$x, unem.k.smooth.wide$y, 
      col = "black", lty = "solid", lwd = 2)
lines(unem.k.smooth.narrow$x, unem.k.smooth.narrow$y, 
      col = "black", lty = "dotdash")
abline(lm(unem.ts~time(unem.ts)), lty = "dotted", col = "black")
```

Continuing the insights from our EDA, the time series of unemployment rate has an upward trend and show some quadratic behavior. Therefore we can estimate a model with quadratic term of time. We attempt to explain seasonal behavior using a dummy variable for each month. Candidate Models are:

$$X_t = \beta_0 + \beta_t time + \beta_m month + \epsilon$$

$$X_t = \beta_0 + \beta_t time + \beta_{t2} time^2 +  \mathbf{\beta_m} \mathbf{month} + \epsilon$$

where time is an annual unit, each additional month is expressed as a fraction of the year. "month" is an categorical variable that is broken down into indicator variables.

```{r}
# Preparing data
unem.ts = ts(unem.data$UNRATENSA, frequency = 12, start = c(1948,1)) 

unem.train.ts = window(unem.ts, end = c(2015,12))
unem.test.ts = window(unem.ts, start = c(2016,01))

y.lm = as.numeric(unem.train.ts)
t.lm = as.numeric(time(unem.train.ts))
mon.lm = as.factor(cycle(unem.train.ts))
```

```{r}
unem.lm = lm(y.lm ~ t.lm + mon.lm)
unem.lm.quad = lm(y.lm ~ t.lm + I(t.lm^2) + mon.lm)

AIC(unem.lm)
AIC(unem.lm.quad)
```

```{r}
summary(unem.lm.quad)
```

```{r}
library(sandwich)
car::linearHypothesis(unem.lm.quad, c("mon.lm2 = 0", "mon.lm3 = 0",
                                      "mon.lm4 = 0", "mon.lm5 = 0",
                                      "mon.lm6 = 0", "mon.lm7 = 0",
                                      "mon.lm8 = 0", "mon.lm9 = 0",
                                      "mon.lm10 = 0", "mon.lm11 = 0",
                                      "mon.lm12 = 0"), vcov = vcovHC)
```

Our quadratic model perform slightly better than the linear model by AIC and Adjusted R-squared. The F-statistic and F-test p-value strongly reject that null hypothesis that our coefficients are not jointly significant thus support explanatory power of our model. The second F-test result also provide evidence that our month variable is significant. We will proceed with this quadratic model for a better fit. Our estimated model is specified as:

$$\hat{X_t} = -3389 + 3.396 time - 0.0008487 time^2 +  \beta_m month -0.805\cdot I(Apr) -0.9518\cdot I(May) -0.5144\cdot I(Jul) \\ - 0.8229\cdot I(Aug) - 1 \cdot I(Sep) -1.169 \cdot I(Oct) -0.9982 \cdot I(Nov) -0.9596 \cdot I(Devc)$$

Notice that we have dropped some month indicator variables in the specification, because they are not statistical different from the base variable January. Along with the negative sign of the significant indicator variables, the estimations agrees with our earlier month plot in the EDA section that the beginning and middle of each year tend to have higher unemployment rates.

```{r}
plot(effects::allEffects(unem.lm.quad)[c(1,3)], 
     main = "Effect Plots")
```

The time effect plot above shows the fitted curve with a positive, gradually leveling slope and expanding confidence interval with the increase in time. Also, the month effect plot show discrete levels and the model clearly discriminate early and mid year from the other months. Both plots align with our EDA findings. To further examine the internal validity of our model, we evaluate the validity of our model by the 6 CLM assumptions:

1. Linearity in Parameters: This is a weak assumption, we have specified our model with linear coefficients.

2. Random sample of data: We clealy have violated this assumption because the observations are serially correlated, as demonstrated in the autocorrelation plots in the EDA. The strongly time dependent residuals plotted below demonstrates that our observations could not have been independent in the first place.

```{r}
plot(unem.lm.quad$residuals, type = "l", 
     main = "Residuals Time Plot - linear regression model")
```

3. No perfect co-linearity: Each year has 12 months, therefore the time variable is not correlated with month.

4. Zero-conditional mean. From the residuals vs fitted value plot, there is a clear curvature of the loess curve from line zero. We tried a separate model with the cubic term of time but the curvature was only flipped not flattened. We could be missing an important variable here. This assumption is violated.

```{r}
par(mfrow = c(1,2))
plot(unem.lm.quad, which = 1)
plot(unem.lm.quad, which = 3)
abline(h = c(sqrt(2),sqrt(3)), col = "green", lty = "dotted")
```

5. Homoskedasticity of errors: The variance of residuals noticeably expand towards higher fitted values. The Loess curve on the scale-location plot clearly picks up at the same time. The Breusch-Pagan test strongly reject the null hypothesis of homoskedasticity. This assumption is violated. 

```{r}
lmtest::bptest(unem.lm.quad)
```

6. Normally distributed error: From the normal QQ plot and histogram, our residuals are clearly right skewed. The Shapiro test also strongly reject the null hypothesis that our residuals are normally distributed.

```{r}
par(mfrow = c(1,2))
hist(unem.lm.quad$residuals, xaxt = "n",
     main = "Residuals of linear regression model")
axis(side = 1, at = seq(-2.5,4.5,0.5))
abline(v = mean(unem.lm.quad$residuals), col = "red")
abline(v = median(unem.lm.quad$residuals), col = "green")
legend("topright", legend = c("Mean", "Median"),
       col = c("red", "green"), bty = "n", 
       lty = c("solid", "solid"))

plot(unem.lm.quad, which = 2)
```

```{r}
shapiro.test(unem.lm.quad$residuals)
```

7. Outlier Analysis (Not an CLM assumption): From the scale-location plot above, we see a number of standardized residuals lying outside the threshold of 2 and 3 standard deviations. This says that our model represents variations in our data poorly. None of the observations are close to cook's distance of 0.5 so there are no extreme outliers.

```{r}
par(mfrow = c(1,2))
plot(unem.lm.quad, which = 5)
abline(h = c(2,3), col = "green", lty = "dotted")
plot(unem.lm.quad, which = 4)
```

(B.i) How well does your model predict the unemployment rate up until June 2017?
(B.ii) What does the unemployment rate look like at the end of 2020? How credible is this estimate?
(B.iii) Compare this forecast to the one produced by the SARIMA model. What do you notice?

### Prediction up until 2017

```{r}
test.time = seq(2015,2017.417,by = (1/12))
test.month = c(seq(1,12),seq(1,6))

test.prediction = predict.lm(object = unem.lm.quad, se.fit = T,
           newdata = data.frame(t.lm = test.time, mon.lm = as.factor(test.month)))
```

```{r}
data.frame("year" = floor(test.time),
           "month" = test.month,
           "lm mean" = test.prediction$fit,
           "lm error" = test.prediction$fit - unem.test$UNRATENSA,
           "SARIMA mean" = as.numeric(f.diff.3$mean),
           "SARIMA error" = as.numeric(f.diff.3$mean) - unem.test$UNRATENSA)
```

```{r}
sarima.err = as.numeric(f.diff.3$mean) - unem.test$UNRATENSA 
lm.err = test.prediction$fit - unem.test$UNRATENSA

sarima.rmse = sqrt(mean(sarima.err^2))
lm.rmse = sqrt(mean(lm.err^2))

cat("SARIMA RMSE: ",sarima.rmse, "\n")
cat("Linear model RMSE: ",lm.rmse, "\n")
```

In comparison with the ARIMA model, the linear regression model has much poorer out-of-sample performance. The above table shows that the linear model predictions are consistently off by 1 to 2 units, while the SARIMA model predictions are only off from -0.4 to +0.2 units. Also, the RMSE of our SARIMA model is only less than 10% of the RMSE of the linear model. 

```{r}
plot(unem.ts, xlim = c(1948,2017.417),
     main = "Raw Series vs Model Fits")

lines(y = unem.lm.quad$fit, x = t.lm, col = "pink")
lines(y = test.prediction$fit, x = test.time, col = "red")

lines(y = m.diff.3$fitted, x = t.lm, col = "cyan")
lines(y = as.numeric(f.diff.3$mean), x = test.time, col = "blue")

legend("topleft", col = c("cyan","blue","pink","red","black"),
       legend = c("SARIMA In-sample-fit",
                  "SARIMA out-of-sample predictions",
                  "lm In-sample-fit",
                  "lm out-of-sample predictions",
                  "raw series"), 
       bty = "n", lty = c("solid","solid","solid","solid","solid"))

```

The above long-term time plot shows that the fitted curve if our linear model fails to pick up most of the random walk variations in the raw series, while the step by step fit of the SARIMA model is quite close. Unless we fit a very high order term for time, it's impossible for the linear model to pick up such variations. On the other hand, seasonal patterns is reasonably approximated by both models, we can see the small ripples in the raw series replicated and matched by both fitted curves.

```{r}
plot(unem.ts, xlim = c(2016,2017.417), ylim = c(0,9),
     main = "Out of sample fit vs Test data")

lines(y = test.prediction$fit, x = test.time, col = "red")
lines(y = test.prediction$fit + 1.96* test.prediction$se.fit,
      x = test.time, col = "red",lty = "dotted")
lines(y = test.prediction$fit - 1.96* test.prediction$se.fit,
      x = test.time, col = "red",lty = "dotted")

lines(y = f.diff.3$mean, x = test.time, col = "blue")
lines(y = as.numeric(f.diff.3$lower[,2]), 
      x = test.time, col = "blue", lty = "dotted")
lines(y = as.numeric(f.diff.3$upper[,2]), 
      x = test.time, col = "blue", lty = "dotted")

legend("bottomleft", col = c("blue","red","black"),
       legend = c("SARIMA out-of-sample predictions",
                  "lm out-of-sample predictions",
                  "raw series"), 
       bty = "n", lty = c("solid","solid","solid"))
```

Within our test region, we see a clear trade-off between the two models. On the one hand, the mean estimates of the SARIMA model is quite close to the test data but its confidence bound widens drastically towards mid 2017 so our predictions lack precision. On the other hand for the linear model, even the lower bound of the estimates are consistently far above the test data. However, the confidence bound is quite narrow. Therefore, the SARIMA model makes less biased but less precise estimates and the linear model makes more biased but more precise estimates.

### Forecast in 2020

```{r}
new.time = seq(2017.500,2020.917,by = (1/12))
new.month = c(seq(7,12),seq(1,12),seq(1,12),seq(1,12))

new.prediction = predict.lm(object = unem.lm.quad, se.fit = T,
           newdata = data.frame(t.lm = new.time, mon.lm = as.factor(new.month)))


new.df = data.frame("year" = floor(new.time),
           "month" = new.month,
           "lm mean estimate" = new.prediction$fit,
           "lm upper estimate" = new.prediction$fit + 1.96* new.prediction$se.fit,
           "lm lower estimate" = new.prediction$fit - 1.96* new.prediction$se.fit)

tail(new.df, 12)
```

The above table shows that forecast of the linear model in 2020 oscillates within 5.5 percent and 6.8 percent. Its confidence intervals don't seem to fluctuate much either.

```{r}
plot(unem.ts, xlim = c(2015,2020.917), ylim = c(-7,12),
     main = "Forecast until end of 2020")

lines(y = unem.lm.quad$fit, x = t.lm, col = "pink")

lines(y = test.prediction$fit, x = test.time, col = "red")
lines(y = test.prediction$fit + 1.96* test.prediction$se.fit,
      x = test.time, col = "red",lty = "dotted")
lines(y = test.prediction$fit - 1.96* test.prediction$se.fit,
      x = test.time, col = "red",lty = "dotted")

lines(y = new.prediction$fit, x = new.time, col = "red")
lines(y = new.prediction$fit + 1.96* new.prediction$se.fit,
      x = new.time, col = "red",lty = "dotted")
lines(y = new.prediction$fit - 1.96* new.prediction$se.fit,
      x = new.time, col = "red",lty = "dotted")

lines(y = m.diff.3$fitted, x = t.lm, col = "cyan")

lines(y = f.diff.3.2020$mean, x = c(test.time,new.time), col = "blue")
lines(y = as.numeric(f.diff.3.2020$lower[,2]), 
      x = c(test.time,new.time), col = "blue", lty = "dotted")
lines(y = as.numeric(f.diff.3.2020$upper[,2]), 
      x = c(test.time,new.time), col = "blue", lty = "dotted")

legend("bottomleft", col = c("blue","cyan","red","pink", "black"),
       legend = c(" SARIMA forecast", "SARIMA fitted",
                  "linear model forecast", "linear model fitted",
                  "raw series"), 
       bty = "n", lty = c("solid","solid","solid","solid"))
```

The time plot above show that the linear model's mean forecasts oscillates around level 6 without clear upward or downward overall trend.  So does its confidence bound. On the other hand the SARIMA model's mean forecast continues the slight downward trend of the raw series and its confidence bound expands drastically to even below zero in 201, which doesn't make much sense. For these reasons, we deem neither models credible to forecast unemployment rate as far as the end of 2020.