---
title: "Lab3_Initial_Legg"
author: "Legg (Ho Man) Yeung"
date: "July 28, 2017"
output: pdf_document
html_document:
  number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())
library(moments)
library(psych)
```


```{r}
unem.data = read.csv("UNRATENSA.csv", header = T)
auto.data = read.csv("TOTALNSA.csv", header = T)
```

# EDA

## Data Overview 

```{r}
str(unem.data)
str(auto.data)
```

```{r}
cbind(head(unem.data),tail(unem.data))
```

```{r}
cbind(head(auto.data),tail(auto.data))
```

```{r}
nrow(unem.data) - nrow(auto.data)
```

- Both datasets are time indexed, accompanied with a key variable of interests. With UNRATENSA, the key variable refers to unemployment rate. With TOTALNSA, the key variable refers to car sale. 

- Both time series presents monthly data. UNRATENSA has 834 observations and starts from 1948-01-01. TOTALNSA has 498 observations  and starts from 1976-01-01. Both ends at 2017-06. UNRATENSA has 28 more years, that is 336 more observations than TOTALNSA.

## Time series Overview

### Time plots and Histograms

```{r}
unem.ts = ts(unem.data$UNRATENSA, frequency = 12, start = c(1948,1))
auto.ts = ts(auto.data$TOTALNSA, frequency = 12, start = c(1976,1))
```

```{r}
ts.plot(unem.ts); title("Unemployment Rate 1948-01 to 2017-06"); 
abline(h = mean(unem.ts), col = "red", lty = "dotdash", lwd = 2)
abline(h = c((mean(unem.ts) + sd(unem.ts)),
             (mean(unem.ts) + 2*sd(unem.ts)),
             (mean(unem.ts) + 3*sd(unem.ts))), 
       col = "red", lty = "dotted", lwd = 1)
abline(h = c((mean(unem.ts) - sd(unem.ts)),
             (mean(unem.ts) - 2*sd(unem.ts))), 
       col = "red", lty = "dotted", lwd = 1)

#abline(lm(unem.ts~time(unem.ts)), lty = "dotted", col = "blue")
legend("topleft", c("Standard Deviations","Mean"), 
       col = c("red","red"), 
       lty = c("dotted", "dotdash"), bty = "n",
       lwd = c(1,2))
```

```{r}
hist(unem.data$UNRATENSA, main = "distribution of unemployment rate",
     xlab = "Unemployment Rate")

abline(v = mean(unem.data$UNRATENSA), col = "red", lty = "dotdash"
       , lwd = 2)
abline(v = c((mean(unem.data$UNRATENSA) + sd(unem.data$UNRATENSA)),
             (mean(unem.data$UNRATENSA) + 2*sd(unem.data$UNRATENSA)),
             (mean(unem.data$UNRATENSA) + 3*sd(unem.data$UNRATENSA))), 
       col = "red", lty = "dotted", lwd = 1)
abline(v = c((mean(unem.data$UNRATENSA) - sd(unem.data$UNRATENSA)),
             (mean(unem.data$UNRATENSA) - 2*sd(unem.data$UNRATENSA))), 
       col = "red", lty = "dotted", lwd = 1)

abline(v = median(unem.data$UNRATENSA), col = "green", lty = "dotdash"
       , lwd = 2)

legend("topright", c("Mean","Standard Deviations", "Median"), 
       col = c("red","red","green"), 
       lty = c("dotdash", "dotted","dotdash"))
```

```{r}
unem.data[unem.data$UNRATENSA > mean(unem.data$UNRATENSA) + 2.5*sd(unem.data$UNRATENSA),]
```

```{r}
# precentage of observations beyond 2, 2.5 and 3 sd
nrow(unem.data[unem.data$UNRATENSA > mean(unem.data$UNRATENSA) 
               + 2*sd(unem.data$UNRATENSA),])/nrow(unem.data)
nrow(unem.data[unem.data$UNRATENSA > mean(unem.data$UNRATENSA) 
               + 2.5*sd(unem.data$UNRATENSA),])/nrow(unem.data)
nrow(unem.data[unem.data$UNRATENSA > mean(unem.data$UNRATENSA)
               + 3*sd(unem.data$UNRATENSA),])/nrow(unem.data)
```

From the above time plot of unemployment, we see clear persistency of the observations. That is, when observations are above or below the mean, they tend to stay so for a while. The overall trend seem to climb slowly upward. Almost 5% of the observations lie 2 standard deviations above the mean, which is made obvious in the right skewed histogram as well. We isolated these observations, the 6 in 1982 and 1983 probably correspond to the early 1980s recessions which officially ended in November 1982. The 3 in 2010 probably correspond to the late 2000s recession which officially ended in June 2009.

```{r}
ts.plot(auto.ts); title("Auto Sales 1976-01 to 2017-06")
abline(h = mean(auto.ts), col = "red", lty = "dotdash", lwd = 2)
abline(h = c((mean(auto.ts) + sd(auto.ts)),
             (mean(auto.ts) + 2*sd(auto.ts)),
             (mean(auto.ts) + 3*sd(auto.ts))), 
       col = "red", lty = "dotted", lwd = 1)
abline(h = c((mean(auto.ts) - sd(auto.ts)),
             (mean(auto.ts) - 2*sd(auto.ts))), 
       col = "red", lty = "dotted", lwd = 1)

#abline(lm(auto.ts~time(auto.ts)), lty = "dotted", col = "blue")
legend("topleft", c("Standard Deviations","Mean"), 
       col = c("red","red"), 
       lty = c("dotted", "dotdash"), bty = "n",
       lwd = c(1,2))
```

```{r}
hist(auto.data$TOTALNSA, main = "distribution of auto sales",
     xlab = "auto sales - thousands of units")

abline(v = mean(auto.data$TOTALNSA), col = "red", lty = "dotdash"
       , lwd = 2)
abline(v = c((mean(auto.data$TOTALNSA) + sd(auto.data$TOTALNSA)),
             (mean(auto.data$TOTALNSA) + 2*sd(auto.data$TOTALNSA)),
             (mean(auto.data$TOTALNSA) + 3*sd(auto.data$TOTALNSA))), 
       col = "red", lty = "dotted", lwd = 1)
abline(v = c((mean(auto.data$TOTALNSA) - sd(auto.data$TOTALNSA)),
             (mean(auto.data$TOTALNSA) - 2*sd(auto.data$TOTALNSA))), 
       col = "red", lty = "dotted", lwd = 1)

abline(v = median(auto.data$TOTALNSA), col = "green", lty = "dotdash"
       , lwd = 2)

legend("topright", c("Mean","Standard Deviations", "Median"), 
       col = c("red","red","green"), 
       lty = c("dotdash", "dotted","dotdash"))
```

```{r}
auto.data[auto.data$TOTALNSA < mean(auto.data$TOTALNSA) - 2*sd(auto.data$TOTALNSA),]
```

```{r}
head(auto.data[auto.data$TOTALNSA > mean(auto.data$TOTALNSA) + 2*sd(auto.data$TOTALNSA),],1)
```

```{r}
# precentage of observations beyond 2 sd
nrow(auto.data[auto.data$TOTALNSA > mean(auto.data$TOTALNSA) 
               + 2*sd(auto.data$TOTALNSA),])/nrow(auto.data)

nrow(auto.data[auto.data$TOTALNSA < mean(auto.data$TOTALNSA) 
               - 2*sd(auto.data$TOTALNSA),])/nrow(auto.data)

```

From the above time plot of auto sales, we see some but weaker persistency than the unemployment series. The overall trend doesn't seem to climb upward or downward. There are more noticeable seasonal patterns than the unemployment series. The histogram is more symmetric and normal. Less than 1.5% observations lie 2 standard deviations above the mean and less than 2.5% observations lie 2 standard deviations below the mean.  We isolated 
these observations, the 5 in 1982 and 1983 and the 5 in 2008 and 2009 probably correspond to the two aforementioned recessions. Notice that these recession related observations in auto sales tend to happen a few months before those in unemployment. There is an unusual spike in 1986, probably attributed to oil prices dropping in half that year.

```{r}
summary(unem.data$UNRATENSA)
summary(auto.data$TOTALNSA)
moments::kurtosis(unem.data$UNRATENSA)
```

### Trend Examination with Smoothers and Decomposition - Unemployment

In this section, we apply smoothers and decomposition to gain some initial insights about the overall trend, seasonality and noise behavior of both series.

```{r}
# Moving Average Filter
unem.ma.smooth.4year = filter(unem.ts, sides = 1, rep(1/48, 48))
unem.ma.smooth.annual = filter(unem.ts, sides = 1, rep(1/12, 12))
unem.ma.smooth.halfyear = filter(unem.ts, sides = 1, rep(1/6, 6))

# Make plot
plot(unem.ts, col = "gray", ylab = "Unemployment Rate",
     main = "Unemployment Rate - Moving Average Filtered")
lines(unem.ma.smooth.4year, col = "magenta")
lines(unem.ma.smooth.annual, col = "red")
lines(unem.ma.smooth.halfyear, col = "blue")
abline(lm(unem.ts~time(unem.ts)), lty = "dotted", col = "black")
```

```{r}
# Kernel smoothing
unem.k.smooth.widest = ksmooth(time(unem.ts), 
                             unem.ts, kernel = c("normal"), 
                             bandwidth = 10)

unem.k.smooth.wide = ksmooth(time(unem.ts), 
                             unem.ts, kernel = c("normal"), 
                             bandwidth = 4)

unem.k.smooth.narrow = ksmooth(time(unem.ts), 
                               unem.ts, kernel = c("normal"), 
                               bandwidth = 0.5)

# Make plot
plot(unem.ts, col = "gray", ylab = "Unemployment Rate",
     main = "Unemployment Rate - Kernel Smoothed")
lines(unem.k.smooth.widest$x, unem.k.smooth.widest$y, col = "magenta")
lines(unem.k.smooth.wide$x, unem.k.smooth.wide$y, col = "red")
lines(unem.k.smooth.narrow$x, unem.k.smooth.narrow$y, col = "blue")
abline(lm(unem.ts~time(unem.ts)), lty = "dotted", col = "black")
```

The asymmetric moving average filters above average over the past 6 months, 12 months and 4 years. The symmetric kernel smoothers attempted 3 bandwidths. In either case, the smoothed series resemble behavior of random walks with drift, evidence by the gradually widened variance and slowly increasing mean towards the right. Formulation for the two smoothers are given here:

  - One-sided Moving Average Smoother

$$m_t = \frac{1}{n+1} \sum_{j = 0}^{n}x_{t-j}$$

where $m_t$ refers to the trend we hope to study, $x_t$ is the raw series, $n$ is the number of past months to include in the averaging.

  - Symmertic Kernel Smoother (symmetric moving average smoother with probability density weight function applied)

$$m_t = \sum_{i=1}^{n}w_i(t)x_{t_i}$$

where density weight function $w_i(t)$ is a function of the kernel function and  $w_i(t) = K(\frac{t-t_i}{b}) / \sum_{j=1}^{n} K(\frac{t-t_j}{b})$. $b$ is the bandwidth which we manipulate. The blue kernel curve used $b=0.5$ to correspond approximately smoothing over about half a year. The smoother curves were generated using higher bandwidth.

```{r}
plot(decompose(unem.ts, type = "additive"))
```

The decomposed trend series resembles that of the moving average and kernel filters. Here the growing variance of the trend is more noticeable, as well as the gradual upward trend. A regular, annual seasonality series was isolated out from the raw series. The random component series is clearly non-stationary. Its variance diminishes over time featured by dramatic spikes before 1965. Clearly, an OLS model would not be the right choice, we should not disregard the non-stationary trend and random components.

The techniques assumes that the raw series is composed of a clear trend, seasonality and random component. The model imposed is:

$$X_t = M_t + S_t + N_t$$

where $X_t$ is the raw series, $M_t$ is the trend, $S_t$ is the seasonal component and $N_t$ is the random component.


### Trend Examination with Smoothers and Decomposition - Unemployment

```{r}
# Moving Average Filter
auto.ma.smooth.4year = filter(auto.ts, sides = 1, rep(1/60, 60))
auto.ma.smooth.annual = filter(auto.ts, sides = 1, rep(1/12, 12))
auto.ma.smooth.halfyear = filter(auto.ts, sides = 1, rep(1/6, 6))

# Make plot
plot(auto.ts, col = "gray", ylab = "Car Sales",
     main = "Car Sales - Moving Average Filtered")
lines(auto.ma.smooth.4year, col = "magenta")
lines(auto.ma.smooth.annual, col = "red")
lines(auto.ma.smooth.halfyear, col = "blue")
abline(lm(auto.ts~time(auto.ts)), lty = "dotted", col = "black")
```

```{r}
# Kernel smoothing
auto.k.smooth.widest = ksmooth(time(auto.ts), 
                             auto.ts, kernel = c("normal"), 
                             bandwidth = 10)

auto.k.smooth.wide = ksmooth(time(auto.ts), 
                             auto.ts, kernel = c("normal"), 
                             bandwidth = 4)

auto.k.smooth.narrow = ksmooth(time(auto.ts), 
                               auto.ts, kernel = c("normal"), 
                               bandwidth = 1)

# Make plot
plot(auto.ts, col = "gray", ylab = "Auto Sales thousands of units",
     main = "Car Sales - Kernel Smoothed")
lines(auto.k.smooth.widest$x, auto.k.smooth.widest$y, col = "magenta")
lines(auto.k.smooth.wide$x, auto.k.smooth.wide$y, col = "red")
lines(auto.k.smooth.narrow$x, auto.k.smooth.narrow$y, col = "blue")
abline(lm(auto.ts~time(auto.ts)), lty = "dotted", col = "black")
```

```{r}
combined.raw = ts.intersect(unem.ts, auto.ts)
unem.intersect.ts = combined.raw[,1]

par(mfrow = c(2,1))

# Kernel smoothing
unem.k.smooth.widest = ksmooth(time(unem.intersect.ts), 
                             unem.intersect.ts, kernel = c("normal"), 
                             bandwidth = 10)

unem.k.smooth.wide = ksmooth(time(unem.intersect.ts), 
                             unem.intersect.ts, kernel = c("normal"), 
                             bandwidth = 4)

unem.k.smooth.narrow = ksmooth(time(unem.intersect.ts), 
                               unem.intersect.ts, kernel = c("normal"), 
                               bandwidth = 0.5)

# Make plot
plot(unem.intersect.ts, col = "gray", ylab = "Unemployment Rate",
     main = "Unemployment Rate - Kernel Smoothed")
lines(unem.k.smooth.widest$x, unem.k.smooth.widest$y, col = "magenta")
lines(unem.k.smooth.wide$x, unem.k.smooth.wide$y, col = "red")
lines(unem.k.smooth.narrow$x, unem.k.smooth.narrow$y, col = "blue")
abline(lm(unem.ts~time(unem.ts)), lty = "dotted", col = "black")

# Kernel smoothing
auto.k.smooth.widest = ksmooth(time(auto.ts), 
                             auto.ts, kernel = c("normal"), 
                             bandwidth = 10)

auto.k.smooth.wide = ksmooth(time(auto.ts), 
                             auto.ts, kernel = c("normal"), 
                             bandwidth = 4)

auto.k.smooth.narrow = ksmooth(time(auto.ts), 
                               auto.ts, kernel = c("normal"), 
                               bandwidth = 0.5)

# Make plot
plot(auto.ts, col = "gray", ylab = "Auto Sales thousands of units",
     main = "Car Sales - Kernel Smoothed")
lines(auto.k.smooth.widest$x, auto.k.smooth.widest$y, col = "magenta")
lines(auto.k.smooth.wide$x, auto.k.smooth.wide$y, col = "red")
lines(auto.k.smooth.narrow$x, auto.k.smooth.narrow$y, col = "blue")
abline(lm(auto.ts~time(auto.ts)), lty = "dotted", col = "black")
```

Compared to the unemployment series, the auto sale series exhibit less downhill-uphill-downhill behavior. It resembles less of a random walk and drift is not entirely apparent. Seasonally pattern is also stronger. We plotted the two series at the same time interval and kernel bandwidth for direct comparison.

```{r}
plot(decompose(auto.ts, type = "additive"))
```

(Decomposition Assumption, Findings of Noise of Inconsistent Variance)
(Trend is sloght upward trend, doesn't look like a random walk. Compared to unemployment it is more stable)
(Seasonality seem regular)
(Noise is clearly not stationary)
(We cannot use regression mode)


## Establish Stationarity

### Seasonality and Unit Root Investigation -- unemployment rate

```{r}
monthplot(unem.ts);title("monthly plot Unemployment Rate")
```

```{r}
astsa::lag1.plot(unem.ts,16) 
```

```{r}
par(mfrow = c(2,1))
acf(unem.ts, lag.max = 61, main = ""); title("ACF Unemployment Rate")
pacf(unem.ts, lag.max = 61, main = ""); title("PACF Unemployment Rate")
```

(monthly plot shows higher values in the beginning and mid year)
(can difference it in SARIMA, if linear regression should use dummy for Jan Feb and Jun July)

(weak seasonality, probably no need for seasonal difference)
(strongest correlation with first lag, then weaker and weaker lags)

(acf slow decay, random walk with drift)
(some sign of seasonality -- note the local peak at lag 12, 24, 36, 48)

(pacf most significant at lag 1 can be AR(1))
(pacf also show sign at lag 12, 25,37,49 , can be a seasonal MA component)

```{r}
unem.ts.diff12 = diff(unem.ts, lag = 12)
```

```{r}
par(mfrow = c(2,1))
ts.plot(unem.ts)
abline(h = mean(unem.ts), col = "red", lty = "dotted")
title("Raw series - Unemployment Rate")
ts.plot(unem.ts.diff12)
title("Seasonally Differenced - Unemployment Rate")
abline(h = mean(unem.ts.diff12), col = "red", lty = "dotted")
```

(Seasonal Regularities Clearly Removed, Trend is less persistent)

```{r}
par(mfrow = c(2,1))
acf(unem.ts.diff12, lag.max = 61, main = "")
title("ACF Seasonally Diffenced Unemployment Rate")
pacf(unem.ts.diff12, lag.max = 61, main = "")
title("PACF Seasonally Diffenced Unemployment Rate")
```

(pacf sees sign lags 13, 25, 37 without much echo of graudal positive decay in acf --> seasonal MA(1) )
(Seasonal Differencing may not be necessary --> Seasonal MA(1) can be a sign that we have over differenced the series)

(pacf sharp drop lag 1, echoed by acf gradual drop from lag 1, AR(1))
(pacf some sign lags 2-4, can be AR(2-4) components, hard to tell from acf, let model loop judge)

Possible model SARIMA(4,0,0)(0,1,1)

```{r}
unem.ts.diff = diff(unem.ts, lag = 1)
```

```{r}
tseries::adf.test(unem.ts)
tseries::pp.test(unem.ts)
tseries::adf.test(unem.ts.diff)
tseries::pp.test(unem.ts.diff)
tseries::adf.test(unem.ts.diff12)
tseries::pp.test(unem.ts.diff12)
```

(ADF failed to reject raw series, unit root is present)
(Augemented Dicky Fuller Test reject first differenced series more strongly than seasonally differenced series. First differencing should be enough. Seasonality can be taken care of by seasonal AR and MA )

(Should not do both seasonally and first differencing)

```{r}
par(mfrow = c(3,1))

ts.plot(unem.ts)
abline(h = mean(unem.ts), col = "red", lty = "dotted")
title("Raw series - Unemployment Rate")

ts.plot(unem.ts.diff12)
abline(h = mean(unem.ts.diff12), col = "red", lty = "dotted")
title("Seasonally Differenced - Unemployment Rate")

ts.plot(unem.ts.diff)
title("First Differenced - Unemployment Rate")
abline(h = mean(unem.ts.diff), col = "red", lty = "dotted")
```

```{r}
par(mfrow = c(2,1))

ts.plot(unem.ts)
abline(h = mean(unem.ts), col = "red", lty = "dotted")
title("Raw series - Unemployment Rate")

ts.plot(unem.ts.diff12)
abline(h = mean(unem.ts.diff12), col = "red", lty = "dotted")
title("Seasonally Differenced - Unemployment Rate")

ts.plot(unem.ts.diff)
title("First Differenced - Unemployment Rate")
abline(h = mean(unem.ts.diff), col = "red", lty = "dotted")
```

```{r}
par(mfrow = c(2,1))
acf(unem.ts.diff, lag.max = 61, main = "")
title("ACF First Difference Unemployment Rate")
pacf(unem.ts.diff, lag.max = 61, main = "")
title("PACF First Difference Unemployment Rate")
```

(long memory seasonal AR(1) and seasonal MA(1))
(pacf show some significance lag 2-9 , without much echo in acf --> let loop figure it out)

possible SARIMA(9,1,q)(1,0,1)

Two possible transformations -- SARIMA(4,0,q)(P,1,1), SARIMA(9,1,q)(1,0,1), 








### Seasonality Investigation -- Auto Sales

```{r}
monthplot(auto.ts);title("monthly plot Autosales")
```

```{r}
astsa::lag1.plot(auto.ts,16)
```


```{r}
par(mfrow = c(2,1))
acf(auto.ts, lag.max = 61, main = ""); title("ACF Autosales")
pacf(auto.ts, lag.max = 61, main = ""); title("PACF Autosales")
```

(monthly plot shows more discrete values)
(seasonality is much stronger. clearly correlated with lag 12)
(should seasonal difference it)

(acf slow decay but show clearn local maximum at lag 12, 24, 36 , 48)

(pacf show sign at lag 1 and 12, AR(1) and SAR(1))

```{r}
auto.ts.diff12 = diff(auto.ts, lag = 12)
```

```{r}
par(mfrow = c(2,1))
ts.plot(auto.ts, main = "") 
title("Raw series - Auto Sales")
ts.plot(auto.ts.diff12, main = "")
title("Seasonally Differenced - Auto Sales")
```

(Regular Seasonal Pattern Clearly Removed)

```{r}
par(mfrow = c(2,1))
acf(auto.ts.diff12, lag.max = 61, main = "")
title("ACF for Seasonally Differenced Autosales")
pacf(auto.ts.diff12, lag.max = 61, main = "")
title("PACF for Seasonally Differenced Autosales")
```

(pacf Still see -ve autocorrelation on Lag 1,2 and 3, acf after lag 3 shows gradual decay --> can be seasonal AR(3))
(pacf still see sharp drop at lag 1 and acf still see graudual decay from lag 1)
(pacf see sign, gradual drop lag 2-5, can be a MA(1) as well)


```{r}
auto.ts.diff = diff(auto.ts, lag = 1)
```

```{r}
tseries::adf.test(auto.ts)
tseries::pp.test(auto.ts)
tseries::adf.test(auto.ts.diff)
tseries::pp.test(auto.ts.diff)
tseries::adf.test(auto.ts.diff12)
tseries::pp.test(auto.ts.diff12)
```

(all TS reject Ho of unit root, no need for first differencing)

```{r}
par(mfrow = c(3,1))
ts.plot(auto.ts)
abline(h = mean(auto.ts), col = "red", lty = "dotted")
title("Raw series - Auto Sales")

ts.plot(auto.ts.diff12)
title("Seasonally Differenced - Auto Sales")
abline(h = mean(auto.ts.diff12), col = "red", lty = "dotted")

ts.plot(auto.ts.diff)
title("First Differenced - Auto Sales")
abline(h = mean(auto.ts.diff), col = "red", lty = "dotted")
```

```{r}
par(mfrow = c(2,1))
acf(unem.ts.diff, lag.max = 61, main = "")
title("ACF First Difference Unemployment Rate")
pacf(unem.ts.diff, lag.max = 61, main = "")
title("PACF First Difference Unemployment Rate")
```

```{r}
par(mfrow = c(2,1))
acf(auto.ts.diff, lag.max = 61, main = "")
title("ACF First Difference Auto Sales")
pacf(auto.ts.diff, lag.max = 61, main = "")
title("PACF First Difference Auto Sales")
```

(Seasonal AR(1))
(pacf Non-seasonal AR(11) -- on acf their effect cancels out each other. Let loop figure this out)

Possible Model SARIMA(11,1,q)(1,0,Q)


## Examine Bivariate Relationship

(Intersect the two time series)

```{r}
# Intersect the series
#combined.raw = ts.intersect(unem.ts, auto.ts)
#unem.intersect.ts = combined.raw[,1]
auto.intersect.ts = combined.raw[,2]

head(combined.raw);tail(combined.raw)
```

```{r}
par(mfrow = c(2,1))
ts.plot(unem.intersect.ts, main = "",
        ylab = "Unemployment Rate")
title("Unemployment Rate")
ts.plot(auto.intersect.ts, main = "",
        ylab = "Auto Sales")
title("Auto Sales")
```

(Auto sales lags behind unemployment rate 1-3 years except for the 2000s)

```{r}
# Function for scatterplot with Loess Curve and regression curve
scatter.loess.lm.plot = function(y, x, xlab, ylab, title){
  
  plot(x = x, y = y, xlab = xlab, ylab = ylab)
  title(title)
  
  abline(lm(y~x), col = "green", lty = "dotted")
  
  order.pred = order(x)
  smooth.stand = loess(formula = y~x, 
                       weights = rep(1,length(x)))
  lines(x = x[order.pred],
        y = predict(smooth.stand)[order.pred],
        lty = "solid", col = "red")
  
  legend("topright", 
         legend = c("regression line", "Loess curve"),
         col = c("green", "red"), 
         lty = "dotted", "solid", bty = "n")
}
```


```{r}
scatter.loess.lm.plot(y = unem.intersect.ts,
                      x = auto.intersect.ts,
                      xlab = "Auto Sales",
                      ylab = "Unemployment",
                      title = "Unemployment vs Autosales")
```

```{r}
cat("Corr(Unemployment, Autosales):", cor(auto.intersect.ts,unem.intersect.ts))
```

(Disregard values change according to time, the two values have a moderate -ve correlation )
(Relationship is possibly non-linear)

```{r}
scatter.loess.lm.plot(y = as.vector(aggregate(unem.intersect.ts)),
                      x = as.vector(aggregate(auto.intersect.ts)),
                      xlab = "Annual Auto Sales",
                      ylab = "Annual Unemployment",
                      title = "Annual Unemployment vs Annual Autosales")
```

```{r}
# cbind(aggregate(unem.intersect.ts), aggregate(auto.intersect.ts))
cat("Corr(Annual Unemployment, Annual Autosales):", cor(aggregate(auto.intersect.ts),aggregate(unem.intersect.ts)))
```

(Annual, aggregated series have stronger correlation)
(Less non-linear than the monthly series. Elimination of seasons make overall trend correlation clearer but also lost the non-linear relationship coming from the different seasonalities between the series)


## Examine cross-correlation

- Scatter Plots with lags

CCF Plots here

```{r}
astsa::lag2.plot(auto.intersect.ts, unem.intersect.ts,16)
```

(The correlation with high order lags are still mildly non-linear)
(it says that behavior of unemployment rate may be different for high auto sales vs low auto sales)

```{r}
astsa::lag2.plot(unem.intersect.ts, auto.intersect.ts,12)
```

(on the other hand, the ccf matrices of auto sales against unem makes better sense, and the relationship seem quite linear and intuitive. strongest at lag 1)


```{r}
ccf(auto.intersect.ts, unem.intersect.ts, main = "")
```

(CCF strongest at -ve lags of unem and lag 0 of auto)
(auto sales lags behind)

```{r}
tseries::po.test(cbind(auto.intersect.ts, unem.intersect.ts))
```

```{r}
unem.auto.lm = lm(unem.intersect.ts~auto.intersect.ts)
summary(unem.auto.lm)
```

```{r}
library(car)
car::residualPlot(unem.auto.lm)
```

(strong curvature. first order auto doesn't effectively explain variations in unem)

```{r}
par(mfrow = c(3,1))
ts.plot(unem.intersect.ts, main = "",
        ylab = "Unemployment Rate")
title("Unemployment Rate")
ts.plot(auto.intersect.ts, main = "",
        ylab = "Auto Sales")
title("Auto Sales")
unem.auto.lm.res = resid(unem.auto.lm)
plot(unem.auto.lm.res, xlab = "t", ylab = "Residuals",
     lty = 1, pch = 1, type = "l")
title("Residuals from the Linear Regression of Unemployment Rate on Auto Sales")
```

```{r}
unem.auto.lm.res = resid(unem.auto.lm)
plot(unem.auto.lm.res, xlab = "t", ylab = "Residuals",
     lty = 1, pch = 1, type = "l")
title("Residuals from the Linear Regression of Unemployment Rate on Auto Sales")
```

```{r}
par(mfrow = c(2,1))
acf(unem.auto.lm.res,61)
pacf(unem.auto.lm.res,61)
```


(The residual series is clearly time-dependent and still picks up the trend in the unemployment rate)
(acf and pacf still looks seasonal and persistent)
(Evidence for existence of linear combination bewtween the two series is not strong)

(Unlikely that auto , or lags of auto can effectively explain variations in unem. but the other way round may better)